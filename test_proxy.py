#!/usr/bin/env python3
"""
æµ‹è¯•OpenAIä»£ç†çš„è„šæœ¬
"""
import requests
import json
import time

# ä»£ç†é…ç½®
PROXY_URL = "http://127.0.0.1:8080"
WEB_URL = "http://127.0.0.1:8081"

def test_proxy():
    """æµ‹è¯•ä»£ç†åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯• OpenAI ä»£ç†...")
    
    # æ¨¡æ‹ŸOpenAI APIè¯·æ±‚
    test_data = {
        "model": "gpt-3.5-turbo",
        "messages": [
            {"role": "user", "content": "Hello, this is a test message!"}
        ],
        "max_tokens": 100
    }
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer sk-test-key-for-demo"
    }
    
    try:
        print(f"ğŸ“¡ å‘é€è¯·æ±‚åˆ°ä»£ç†æœåŠ¡å™¨: {PROXY_URL}/v1/chat/completions")
        
        # å‘é€è¯·æ±‚åˆ°ä»£ç†
        response = requests.post(
            f"{PROXY_URL}/v1/chat/completions",
            headers=headers,
            json=test_data,
            timeout=30
        )
        
        print(f"ğŸ“Š å“åº”çŠ¶æ€ç : {response.status_code}")
        print(f"ğŸ“ å“åº”å†…å®¹: {response.text[:200]}...")
        
        # ç­‰å¾…ä¸€ä¸‹è®©è¯·æ±‚è¢«è®°å½•
        time.sleep(1)
        
        print(f"ğŸŒ è¯·åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹ç›‘æ§ç•Œé¢: {WEB_URL}")
        print("âœ… æµ‹è¯•å®Œæˆï¼æ‚¨åº”è¯¥èƒ½åœ¨Webç•Œé¢ä¸­çœ‹åˆ°è¿™ä¸ªè¯·æ±‚çš„è¯¦ç»†ä¿¡æ¯ã€‚")
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

def test_multiple_requests():
    """æµ‹è¯•å¤šä¸ªè¯·æ±‚"""
    print("\nğŸ”„ å‘é€å¤šä¸ªæµ‹è¯•è¯·æ±‚...")
    
    test_cases = [
        {
            "model": "gpt-3.5-turbo",
            "messages": [{"role": "user", "content": "What is Python?"}],
            "max_tokens": 50
        },
        {
            "model": "gpt-4",
            "messages": [{"role": "user", "content": "Explain machine learning"}],
            "max_tokens": 100
        },
        {
            "model": "text-davinci-003",
            "prompt": "Write a short poem about coding",
            "max_tokens": 80
        }
    ]
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer sk-test-key-for-demo"
    }
    
    for i, test_data in enumerate(test_cases, 1):
        try:
            print(f"ğŸ“¤ å‘é€è¯·æ±‚ {i}/3...")
            
            # æ ¹æ®æ¨¡å‹é€‰æ‹©ä¸åŒçš„ç«¯ç‚¹
            if "davinci" in test_data.get("model", ""):
                endpoint = f"{PROXY_URL}/v1/completions"
            else:
                endpoint = f"{PROXY_URL}/v1/chat/completions"
            
            response = requests.post(
                endpoint,
                headers=headers,
                json=test_data,
                timeout=30
            )
            
            print(f"   çŠ¶æ€ç : {response.status_code}")
            time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿ
            
        except Exception as e:
            print(f"   âŒ è¯·æ±‚ {i} å¤±è´¥: {e}")
    
    print("âœ… å¤šè¯·æ±‚æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ OpenAI ä»£ç†æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # åŸºæœ¬æµ‹è¯•
    test_proxy()
    
    # å¤šè¯·æ±‚æµ‹è¯•
    test_multiple_requests()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
    print(f"   â€¢ ä»£ç†æœåŠ¡å™¨: {PROXY_URL}")
    print(f"   â€¢ ç›‘æ§ç•Œé¢: {WEB_URL}")
    print("   â€¢ æ‰€æœ‰è¯·æ±‚éƒ½ä¼šè¢«è®°å½•å’Œæ˜¾ç¤ºåœ¨Webç•Œé¢ä¸­")
    print("=" * 60)
